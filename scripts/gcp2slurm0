#!/bin/bash
#  gcp2slurm0 (gsutil cp) to slurm0
#    https://cloud.google.com/storage/docs/gsutil/commands/cp
#
#  `gsutil cps`
#    copy data between your local file system and the cloud
#
#   Examples:
#     # Upload all text files to a bucket
#     $ gsutil cp *.txt gs://$MY_BUCKET
#
#     # Download all text files from a bucket
#     $ gsutil cp gs://$MY_BUCKET/*.txt .
#
#     # The -r option to copy an entire directory tree
#     $ gsutil cp -r $DIR gs://$MY_BUCKET
#
#     # The -m option for a parallel multi-threaded/multi-processing copy
#     $ gsutil -m cp -r $DIR gs://$MY_BUCKET
#
#     # The -I option to specify a list
#     #   to upload
#     $ cat $FILE_LIST | gsutil -m cp -I gs://$MY_BUCKET
#
#     #   to upload
#     $ cat $FILE_LIST | gsutil -m cp -I $DIR

# Function definition
run() {
  COMMAND=$1
  echo "$COMMAND"
  eval $COMMAND
}

# You may change this part
FILE=train_data.jsonl

#USER_TAG=${1:-tkim}
USER_TAG=${1:-slurm0}
BUCKET_NAME=${2:-object-storage}
# https://cloud.google.com/compute/docs/regions-zones
REGION=${3:-us-central1}
UNIQUE_BUCKET_NAME=$USER_TAG-$BUCKET_NAME-$REGION
# You may change this part

MY_BUCKET=$UNIQUE_BUCKET_NAME
run "gsutil cp $FILE gs://$MY_BUCKET"

# TODO: troubleshoot
# Tip. Create a temp file and copy it first as a test.
# touch file.tmp
#FILE_LIST="file.tmp"  # for a test
# FILE_LIST="file.tmp train_data.jsonl"
#FILE_LIST="file.tmp train_data.jsonl enwiki-latest-pages-articles.xml.bz2"

#run "cat $FILE_LIST | gsutil -m cp -I gs://$MY_BUCKET"
# If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o "GSUtil:parallel_process_count=1"`. Note that multithreading is still available even if you disable multiprocessing.
# InvalidUrlError: Unrecognized scheme "{"id": "73822620", "revid": "39361517", "url": "https"
# CommandException: 1 file/object could not be transferred.
