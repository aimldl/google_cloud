{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDcI0SYySZiu"
   },
   "source": [
    "# [CEPF L300]: Tune Gemini Model by using Supervised Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D59iF36T62k"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fEBa5FbT-dc"
   },
   "source": [
    "### Install Vertex AI SDK and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0M04I5j3_KY5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyKgURhIUnAM"
   },
   "source": [
    "## Set Project and Location\n",
    "\n",
    "First, you have to set your project_id, location, and bucket_name. You can also use an existing bucket within the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4acO9tVcU1Ey",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION=$['europe-west4']\n"
     ]
    }
   ],
   "source": [
    "project_id_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = project_id_output[0]\n",
    "REGION = !gcloud compute project-info describe --format=\"value[](commonInstanceMetadata.items.google-compute-default-region)\"\n",
    "LOCATION = REGION[0]\n",
    "print(f\"REGION=${REGION}\")\n",
    "\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-model-dataset\"\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkBZ-e85UeiI"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jsnIinC4UfZq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    HarmCategory,\n",
    "    HarmBlockThreshold,\n",
    "    GenerationConfig,\n",
    ")\n",
    "from vertexai.preview.tuning import sft\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbaPSIO4_iur"
   },
   "source": [
    "## Generate the training and validation dataset files\n",
    "\n",
    "To create a tuning job, you use a Q&A with a context dataset in JSON format.\n",
    "\n",
    "Supervised fine-tuning offers a solution, as it allows focused adaptation of foundation models to new tasks. You can create a supervised text model tuning job using the Google Cloud console, API, or the Vertex AI SDK for Python.Â For more information, refer to the [documentation page](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-use-supervised-tuning),\n",
    "\n",
    "But how do you ensure your data is primed for success with supervised fine-tuning? Here are the critical areas to focus on:\n",
    "\n",
    "- **Domain Alignment:** Supervised fine-tuning thrives on smaller datasets, but they must be highly relevant to your downstream task. Look for data that closely mirrors the domain you will encounter in real-world use cases.\n",
    "- **Labeling Accuracy:** Noisy labels sabotage even the best technique. Prioritize accuracy in your annotations and labeling.\n",
    "- **Noise Reduction:** Outliers, inconsistencies, or irrelevant examples hurt model adaptation. Implement preprocessing, such as removing duplicates, fixing typos, and verifying that data conforms to your task's expectations.\n",
    "- **Distribution:** A diverse range of examples helps your model generalize better within the confines of your target task. Refrain from overloading the process with excessive variance that strays from your core domain.\n",
    "- **Balanced Classes:** For classification tasks, try to keep a reasonable balance between different classes to avoid the model learning biases towards a specific class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivFjWO5M-Z8H"
   },
   "source": [
    "### Fetching data from BigQuery\n",
    "\n",
    "Your model tuning dataset must be in a JSONL format where each line contains a single training example. You must make sure that you include instructions.\n",
    "\n",
    "You will use the [StackOverflow dataset](https://cloud.google.com/blog/topics/public-datasets/google-bigquery-public-datasets-now-include-stack-overflow-q-a) on BigQuery Public Datasets, limiting to questions with the `python` tag, and accepted answers for answers since 2020-01-01.\n",
    "\n",
    "You use a helper function to read the data from BigQuery and create a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2JIlL-aVbNPg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_bq_query(sql: str) -> Union[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run a BigQuery query and return the job ID or result as a DataFrame\n",
    "    Args:\n",
    "        sql: SQL query, as a string, to execute in BigQuery\n",
    "    Returns:\n",
    "        df: DataFrame of results from query,  or error, if any\n",
    "    \"\"\"\n",
    "\n",
    "    bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return DataFrame\n",
    "    df = client_result.result().to_arrow().to_pandas()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11WLzqp-b59c"
   },
   "source": [
    "Next you write the query. Limit your example to 550.\n",
    "\n",
    "**TODO:** Update the query below to limit the results to 550."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gLC_elwzb3ZF",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job_id: 9ac4d829-bffd-4b1b-bb24-8653c0440c53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mark_area resetting the Y-axis domain (Altair)...</td>\n",
       "      <td>&lt;p&gt;Area charts include zero by default. To cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure how a node is passed as parameter in ...</td>\n",
       "      <td>&lt;p&gt;I will try to explain with a simple example...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loop through XML in Python&lt;p&gt;My data set is as...</td>\n",
       "      <td>&lt;p&gt;Looping can be done in a list comprehension...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Runtime error in CSES problem set Missing Numb...</td>\n",
       "      <td>&lt;p&gt;You might want to try:&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;n=in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python django logging: One single logger with ...</td>\n",
       "      <td>&lt;p&gt;Best solution I found was to create multipl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  mark_area resetting the Y-axis domain (Altair)...   \n",
       "1  Not sure how a node is passed as parameter in ...   \n",
       "2  Loop through XML in Python<p>My data set is as...   \n",
       "3  Runtime error in CSES problem set Missing Numb...   \n",
       "4  python django logging: One single logger with ...   \n",
       "\n",
       "                                         output_text  \n",
       "0  <p>Area charts include zero by default. To cha...  \n",
       "1  <p>I will try to explain with a simple example...  \n",
       "2  <p>Looping can be done in a list comprehension...  \n",
       "3  <p>You might want to try:</p>\\n<pre><code>n=in...  \n",
       "4  <p>Best solution I found was to create multipl...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_overflow_df = run_bq_query(\n",
    "    \"\"\"SELECT\n",
    "           CONCAT(q.title, q.body) AS input_text,\n",
    "           a.body AS output_text\n",
    "       FROM `bigquery-public-data.stackoverflow.posts_questions` q\n",
    "       JOIN `bigquery-public-data.stackoverflow.posts_answers` a\n",
    "         ON q.accepted_answer_id = a.id\n",
    "       WHERE q.accepted_answer_id IS NOT NULL\n",
    "         AND REGEXP_CONTAINS(q.tags, \"python\")\n",
    "         AND a.creation_date >= \"2020-01-01\"\n",
    "       LIMIT 550\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "stack_overflow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b404hW8jcRDQ"
   },
   "source": [
    "There should be 550 questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mUg-lF61cUVI",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    }
   ],
   "source": [
    "print(len(stack_overflow_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHda8BzbmRMC"
   },
   "source": [
    "### Adding instructions\n",
    "Finetuning language models on a collection of datasets phrased as instructions improve model performance and generalization to unseen tasks [(Google, 2022)](https://arxiv.org/pdf/2210.11416.pdf).\n",
    "\n",
    "An instruction refers to a specific directive or guideline that conveys a task or action to be executed. These instructions can be expressed in various forms, such as step-by-step procedures, commands, or rules. When you don't use the instructions, it's only a question and answer. The instruction tells the large language model what to do. You want them to answer the question. You have to give a hint about the task you want to perform. Extend the dataset with an instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XIy7BjKWmu5j",
    "tags": []
   },
   "outputs": [],
   "source": [
    "INSTRUCTION_TEMPLATE = f\"\"\"\\\n",
    "You are a helpful Python developer \\\n",
    "You are good at answering Stackoverflow questions \\\n",
    "Your mission is to provide developers with helpful answers that work\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tM_f1b3n4TK"
   },
   "source": [
    "Create a new column for the `INSTRUCTION_TEMPLATE`. Use a new column and do not overwrite the existing one because you might want to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UJpAJG8uoE7F",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "      <th>input_text_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mark_area resetting the Y-axis domain (Altair)...</td>\n",
       "      <td>&lt;p&gt;Area charts include zero by default. To cha...</td>\n",
       "      <td>You are a helpful Python developer You are goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure how a node is passed as parameter in ...</td>\n",
       "      <td>&lt;p&gt;I will try to explain with a simple example...</td>\n",
       "      <td>You are a helpful Python developer You are goo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  mark_area resetting the Y-axis domain (Altair)...   \n",
       "1  Not sure how a node is passed as parameter in ...   \n",
       "\n",
       "                                         output_text  \\\n",
       "0  <p>Area charts include zero by default. To cha...   \n",
       "1  <p>I will try to explain with a simple example...   \n",
       "\n",
       "                                 input_text_instruct  \n",
       "0  You are a helpful Python developer You are goo...  \n",
       "1  You are a helpful Python developer You are goo...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_overflow_df[\"input_text_instruct\"] = INSTRUCTION_TEMPLATE\n",
    "\n",
    "stack_overflow_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNMMxaB2cZvY"
   },
   "source": [
    "**TODO:**\n",
    "Next, you split the data into training and evaluation. For Extractive Q&A tasks, it's advised 500+ training examples. In this case, you use 440 to generate a tuning job that runs faster. \n",
    "\n",
    "20% of your dataset is used for testing. The `random_state` controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qdrweRsscfgU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records in training dataset: 440\n",
      "Total number of records in validation dataset: 110\n"
     ]
    }
   ],
   "source": [
    "# TODO: Update the test_size to select 20% of data for evaluation\n",
    "train, evaluation = train_test_split(stack_overflow_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Warning - Don't change the following print statements. It is used for score tracking. \n",
    "# Please don't forget to save this notebook script.\n",
    "print('Total number of records in training dataset:',len(train))\n",
    "print('Total number of records in validation dataset:',len(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "      <th>input_text_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>How to get time.sleep working in PyCharm?&lt;pre&gt;...</td>\n",
       "      <td>&lt;p&gt;Add &lt;code&gt;import time&lt;/code&gt; to the top of ...</td>\n",
       "      <td>You are a helpful Python developer You are goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>discord.py :: How would I make a command to ad...</td>\n",
       "      <td>&lt;p&gt;You can create a command that allows modera...</td>\n",
       "      <td>You are a helpful Python developer You are goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How to get one to many like result in a querys...</td>\n",
       "      <td>&lt;p&gt;I think this is one possible solution. You ...</td>\n",
       "      <td>You are a helpful Python developer You are goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Verifying exactly the same variable in python ...</td>\n",
       "      <td>&lt;p&gt;What you are looking for is &lt;code&gt;is&lt;/code&gt;...</td>\n",
       "      <td>You are a helpful Python developer You are goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Difference between \"alpha\" and \"start_alpha\"&lt;p...</td>\n",
       "      <td>&lt;p&gt;The parameter &lt;code&gt;alpha&lt;/code&gt; is used in...</td>\n",
       "      <td>You are a helpful Python developer You are goo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            input_text  \\\n",
       "482  How to get time.sleep working in PyCharm?<pre>...   \n",
       "158  discord.py :: How would I make a command to ad...   \n",
       "15   How to get one to many like result in a querys...   \n",
       "334  Verifying exactly the same variable in python ...   \n",
       "39   Difference between \"alpha\" and \"start_alpha\"<p...   \n",
       "\n",
       "                                           output_text  \\\n",
       "482  <p>Add <code>import time</code> to the top of ...   \n",
       "158  <p>You can create a command that allows modera...   \n",
       "15   <p>I think this is one possible solution. You ...   \n",
       "334  <p>What you are looking for is <code>is</code>...   \n",
       "39   <p>The parameter <code>alpha</code> is used in...   \n",
       "\n",
       "                                   input_text_instruct  \n",
       "482  You are a helpful Python developer You are goo...  \n",
       "158  You are a helpful Python developer You are goo...  \n",
       "15   You are a helpful Python developer You are goo...  \n",
       "334  You are a helpful Python developer You are goo...  \n",
       "39   You are a helpful Python developer You are goo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "      <th>input_text_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>elements from a list to dataframe names for ex...</td>\n",
       "      <td>&lt;p&gt;Having a list&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;list_of_dfs =...</td>\n",
       "      <td>You are a helpful Python developer You are goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input_text  \\\n",
       "count                                                 110   \n",
       "unique                                                110   \n",
       "top     elements from a list to dataframe names for ex...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                              output_text  \\\n",
       "count                                                 110   \n",
       "unique                                                110   \n",
       "top     <p>Having a list</p>\\n<pre><code>list_of_dfs =...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                      input_text_instruct  \n",
       "count                                                 110  \n",
       "unique                                                  1  \n",
       "top     You are a helpful Python developer You are goo...  \n",
       "freq                                                  110  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the **Task 4. Generate the training and validation dataset files** section of the lab instructions and click  **Check my progress** to verify the __Split the dataset for training and evaluation__ objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_MuRRGmfLni"
   },
   "source": [
    "### Generate the JSONL files\n",
    "\n",
    "Prepare your training data in a JSONL (JSON Lines) file and store it in a Google Cloud Storage (GCS) bucket. This format ensures efficient processing. Each line of the JSONL file must represent a single data instance and follow a well-defined schema:\n",
    "\n",
    "`{ \"systemInstruction\": {\"role\": \"system\", \"parts\": [{\"text\": \"instructions\"}]},\n",
    "  \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"question\"}]},{\"role\": \"model\", \"parts\": [{\"text\": \"answering\"}]}]}`\n",
    "\n",
    "This is how it maps to the Pandas df columns:\n",
    "\n",
    "*   `instructions -> input_text_instruct`\n",
    "*   `question -> input_text`\n",
    "*   `answer -> output_text`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fgPXoXOlc0vI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_data_filename = f\"tune_data_stack_overflow_qa.jsonl\"\n",
    "validation_data_filename = f\"validation_data_stack_overflow_qa.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9-oHmx0wfElN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_messages(row):\n",
    "    \"\"\"Formats a single row into the desired JSONL structure\"\"\"\n",
    "    return {\n",
    "      \"systemInstruction\": {\n",
    "        \"role\": \"system\",\n",
    "        \"parts\": [\n",
    "          {\n",
    "            \"text\": row[\"input_text_instruct\"]\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"contents\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"parts\": [\n",
    "            {\n",
    "              \"text\": row[\"input_text\"]\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"model\",\n",
    "          \"parts\": [\n",
    "            {\n",
    "              \"text\": row[\"output_text\"]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8mBwn2jJEkYl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply formatting function to each row, then convert to JSON Lines format\n",
    "tuning_data = train.apply(format_messages, axis=1).to_json(orient=\"records\", lines=True)\n",
    "\n",
    "# Save the result to a JSONL file\n",
    "with open(tuning_data_filename, \"w\") as f:\n",
    "    f.write(tuning_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz9IbouGftaZ"
   },
   "source": [
    "Next, check if the number of rows match with your Pandas df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "w4JfgAijikHp",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the JSONL file: 440\n"
     ]
    }
   ],
   "source": [
    "with open(tuning_data_filename, \"r\") as f:\n",
    "    num_rows = sum(1 for line in f)\n",
    "\n",
    "print(\"Number of rows in the JSONL file:\", num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42u53mHQVZk3"
   },
   "source": [
    "Do the same for the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nBc6ufE0h2zL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply formatting function to each row, then convert to JSON Lines format\n",
    "validation_data = evaluation.apply(format_messages, axis=1).to_json(\n",
    "    orient=\"records\", lines=True\n",
    ")\n",
    "\n",
    "# Save the result to a JSONL file\n",
    "with open(validation_data_filename, \"w\") as f:\n",
    "    f.write(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYGr7h_2ahqb"
   },
   "source": [
    "Next, copy the JSONL files into the Google Cloud Storage bucket you specified or created at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eq0MYC6nxhKy",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://tune_data_stack_overflow_qa.jsonl [Content-Type=application/octet-stream]...\n",
      "Copying file://validation_data_stack_overflow_qa.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [2 files][  1.7 MiB/  1.7 MiB]                                                \n",
      "Operation completed over 2 objects/1.7 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $tuning_data_filename $validation_data_filename $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBq0NMIxa2iD"
   },
   "source": [
    "Check if the files are in the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "cVel0g6pkOiA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1428964  2024-12-12T18:10:27Z  gs://qwiklabs-gcp-01-5b3935109de6-model-dataset/tune_data_stack_overflow_qa.jsonl#1734027027202619  metageneration=1\n",
      "    328751  2024-12-12T18:10:27Z  gs://qwiklabs-gcp-01-5b3935109de6-model-dataset/validation_data_stack_overflow_qa.jsonl#1734027027328621  metageneration=1\n",
      "TOTAL: 2 objects, 1757715 bytes (1.68 MiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsc0xhNGa7ZQ"
   },
   "source": [
    "Create two variables for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "tXzEZFjtkTWJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "TUNING_DATA_URI = f\"{BUCKET_URI}/{tuning_data_filename}\"\n",
    "VALIDATION_DATA_URI = f\"{BUCKET_URI}/{validation_data_filename}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the **Task 4. Generate the training and validation dataset files** section of the lab instructions and click  **Check my progress** to verify the __Store the training and validation files in Cloud Storage__ objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAOu-xJnA54y"
   },
   "source": [
    "## Start a supervised tuning job using Gemini\n",
    "It's time to start your tuning job. Use the `gemini-1.5-pro-002` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "SodJv2vWicfu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "foundation_model = GenerativeModel(\"gemini-1.5-pro-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Create a supervised fine-tuning job with following parameters: \n",
    "\n",
    "* **Tuned model display name:** `StackOverflow Q&A Supervised Tuning Job`\n",
    "* **Source model:** gemini-1.5-pro-002\n",
    "* **Training dataset:** tune_data_stack_overflow_qa.jsonl\n",
    "* **Validation dataset:** validation_data_stack_overflow_qa.jsonl\n",
    "* **Epochs:** 3\n",
    "* **Learning Rate Multiplier:** 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "6e7zBH5foZbC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SupervisedTuningJob\n",
      "SupervisedTuningJob created. Resource name: projects/372089863747/locations/europe-west4/tuningJobs/7765162057824993280\n",
      "To use this SupervisedTuningJob in another session:\n",
      "tuning_job = sft.SupervisedTuningJob('projects/372089863747/locations/europe-west4/tuningJobs/7765162057824993280')\n",
      "View Tuning Job:\n",
      "https://console.cloud.google.com/vertex-ai/generative/language/locations/europe-west4/tuning/tuningJob/7765162057824993280?project=372089863747\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-5ab65744-040f-4f34-901a-5374cd0da94f\" href=\"#view-view-vertex-resource-5ab65744-040f-4f34-901a-5374cd0da94f\">\n",
       "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
       "          <span>View Tuning Job</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-5ab65744-040f-4f34-901a-5374cd0da94f');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/europe-west4/tuning/tuningJob/7765162057824993280?project=372089863747');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/europe-west4/tuning/tuningJob/7765162057824993280?project=372089863747', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-a48bc668-3573-4271-a9ce-0bdde470e2fe\" href=\"#view-view-vertex-resource-a48bc668-3573-4271-a9ce-0bdde470e2fe\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-a48bc668-3573-4271-a9ce-0bdde470e2fe');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/europe-west4/experiments/tuning-experiment-20241212102354106888/runs?project=qwiklabs-gcp-01-5b3935109de6');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/europe-west4/experiments/tuning-experiment-20241212102354106888/runs?project=qwiklabs-gcp-01-5b3935109de6', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/372089863747/locations/europe-west4/models/477289201524539392@1\n",
      "projects/372089863747/locations/europe-west4/endpoints/2273334848426868736\n",
      "<google.cloud.aiplatform.metadata.experiment_resources.Experiment object at 0x7f8cbae09120>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/372089863747/locations/europe-west4/tuningJobs/7765162057824993280',\n",
       " 'tunedModelDisplayName': 'StackOverflow Q&A Supervised Tuning Job',\n",
       " 'baseModel': 'gemini-1.5-pro-002',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://qwiklabs-gcp-01-5b3935109de6-model-dataset/tune_data_stack_overflow_qa.jsonl',\n",
       "  'validationDatasetUri': 'gs://qwiklabs-gcp-01-5b3935109de6-model-dataset/validation_data_stack_overflow_qa.jsonl',\n",
       "  'hyperParameters': {'epochCount': '3',\n",
       "   'learningRateMultiplier': 1.0,\n",
       "   'adapterSize': 'ADAPTER_SIZE_FOUR'}},\n",
       " 'state': 'JOB_STATE_SUCCEEDED',\n",
       " 'createTime': '2024-12-12T18:19:54.760001Z',\n",
       " 'startTime': '2024-12-12T18:20:12.791932Z',\n",
       " 'endTime': '2024-12-12T18:44:54.476552Z',\n",
       " 'updateTime': '2024-12-12T18:44:54.476552Z',\n",
       " 'experiment': 'projects/372089863747/locations/europe-west4/metadataStores/default/contexts/tuning-experiment-20241212102354106888',\n",
       " 'tunedModel': {'model': 'projects/372089863747/locations/europe-west4/models/477289201524539392@1',\n",
       "  'endpoint': 'projects/372089863747/locations/europe-west4/endpoints/2273334848426868736'},\n",
       " 'tuningDataStats': {'supervisedTuningDataStats': {'tuningDatasetExampleCount': '440',\n",
       "   'userInputTokenDistribution': {'sum': '277361',\n",
       "    'min': 84.0,\n",
       "    'max': 9991.0,\n",
       "    'mean': 630.3659090909091,\n",
       "    'median': 443.0,\n",
       "    'p5': 148.0,\n",
       "    'p95': 1550.0,\n",
       "    'buckets': [{'count': 423.0, 'left': 84.0, 'right': 1735.0},\n",
       "     {'count': 13.0, 'left': 1736.0, 'right': 3386.0},\n",
       "     {'count': 2.0, 'left': 3387.0, 'right': 5037.0},\n",
       "     {'count': 2.0, 'left': 8341.0, 'right': 9991.0}]},\n",
       "   'userOutputTokenDistribution': {'sum': '146529',\n",
       "    'min': 14.0,\n",
       "    'max': 8186.0,\n",
       "    'mean': 333.0204545454545,\n",
       "    'median': 230.0,\n",
       "    'p5': 64.0,\n",
       "    'p95': 881.0,\n",
       "    'buckets': [{'count': 435.0, 'left': 14.0, 'right': 1376.0},\n",
       "     {'count': 4.0, 'left': 1377.0, 'right': 2738.0},\n",
       "     {'count': 1.0, 'left': 6825.0, 'right': 8186.0}]},\n",
       "   'userMessagePerExampleDistribution': {'sum': '880',\n",
       "    'min': 2.0,\n",
       "    'max': 2.0,\n",
       "    'mean': 2.0,\n",
       "    'median': 2.0,\n",
       "    'p5': 2.0,\n",
       "    'p95': 2.0,\n",
       "    'buckets': [{'count': 440.0, 'left': 2.0, 'right': 2.0}]},\n",
       "   'userDatasetExamples': [{'role': 'user',\n",
       "     'parts': [{'text': 'How to get time.sleep working in PyCharm?<pre><code>x = a.1\\ny = .5\\nz = input(&quot;Name:&quot;)\\ninput(&quot;Password:&quot;)\\nprint(&quot;Welcome &quot; + z)\\ntime.sleep(x)\\n</code></pre>\\n<p>and time.sleep is not working\\nError:</p>\\n<pre><code>Name:a\\nPassword:a\\nWelcomea\\nTraceback (most recent call last):\\n  File &quot;F:/Python/PROGETTI/Test.py&quot;, line 6, in &lt;module&gt;\\n    time.sleep(x)\\nName...'}]},\n",
       "    {'role': 'model',\n",
       "     'parts': [{'text': '<p>Add <code>import time</code> to the top of your file, then read <a href=\"https://docs.python.org/3/reference/import.html\" rel=\"nofollow noreferrer\">https://docs.python.org/3/reference/import.html</a></p>\\n<pre><code>import time\\n\\nx = a.1\\ny = .5\\nz = input(&quot;Name:&quot;)\\ninput(&quot;Password:&quot;)\\nprint(&quot;Welcome &quot; + z)\\ntime.sleep(x)\\n</code></pre>'}]},\n",
       "    {'role': 'user',\n",
       "     'parts': [{'text': \"discord.py :: How would I make a command to add a word to a filter?<p>I currently have this bit of code to have a filter system.</p>\\n<p>This is at the top of my code;</p>\\n<pre><code>with open('filter.txt', 'r') as f:\\n    global filter\\n    words = f.read()\\n    filter = words.split()\\n</code></pre>\\n<p>While this is in my on_message part of my code;</p>\\n<pre><code>@client.event\\nasync def on_message...\"}]},\n",
       "    {'role': 'model',\n",
       "     'parts': [{'text': '<p>You can create a command that allows moderators to add/append to the list in your filter file.</p>\\n<p>It could look something like this:</p>\\n<pre><code># Instantiates command\\n@client.command(name=&quot;filter&quot;, help=&quot;Adds word to filter&quot;)\\n# Only users with role id can use command\\n@commands.has_any_role(id for moderators)\\nasync def appendFilterList(ctx, word):\\n    # Opens file ...'}]},\n",
       "    {'role': 'user',\n",
       "     'parts': [{'text': 'How to get one to many like result in a queryset<h1>How to achieve <em>one to many like</em> result in a queryset.</h1>\\n<p>I am doing a query that returns results that match checkout date. Is it possible to modify the result so as to return array of rooms under one ref_id where the ref_id and checkout date is matching?.</p>\\n<pre><code># models.py\\nclass Booking(models.Model):\\n    ref_id = models...'}]},\n",
       "    {'role': 'model',\n",
       "     'parts': [{'text': '<p>I think this is one possible solution. You can use <code>serializers.SerializerMethodField()</code> to get all rooms from all bookings with the same <code>ref_id</code> and <code>check_out_date</code>.</p>\\n<pre><code>class BookingsSerializer(serializers.Serializer):\\n    ref_id = serializers.CharField()\\n    rooms = serializers.SerializerMethodField()\\n    check_out_date = serializers.DateField...'}]}],\n",
       "   'totalBillableTokenCount': '423890'}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sft_tuning_job = [ TODO - Insert your code ]\n",
    "\n",
    "sft_tuning_job = sft.train(\n",
    "    tuned_model_display_name=\"StackOverflow Q&A Supervised Tuning Job\",\n",
    "    source_model=foundation_model,\n",
    "    train_dataset=f\"{BUCKET_URI}/tune_data_stack_overflow_qa.jsonl\",\n",
    "    # Optional:\n",
    "    validation_dataset=f\"{BUCKET_URI}/validation_data_stack_overflow_qa.jsonl\",\n",
    "    epochs=3, \n",
    "    learning_rate_multiplier=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LSm5Ns5gjx-"
   },
   "source": [
    "Go to the **Task 5. Start a supervised tuning job using Gemini** section of the lab and click  **Check my progress** to verify the __Start a supervised tuning job using Gemini__ objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgukIEFPlVdD"
   },
   "source": [
    "Next, you retrieve the model resource name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Q3yiKi-KofGK",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/372089863747/locations/europe-west4/tuningJobs/7765162057824993280'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the resource name of the tuning job\n",
    "sft_tuning_job_name = sft_tuning_job.resource_name\n",
    "sft_tuning_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SM1RZVqWKRdg"
   },
   "source": [
    "Tuning takes approximately 100-120 minutes. Wait until the job is finished before you continue after the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Uyug1dw4FAgn",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.2 ms, sys: 4.69 ms, total: 33.9 ms\n",
      "Wall time: 170 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wait for job completion\n",
    "while not sft_tuning_job.refresh().has_ended:\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing the tuning job, go to the **Task 5. Start a supervised tuning job using Gemini** section of the lab and click  **Check my progress** to verify the __Tune Gemini model using supervised fine-tuning__ objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nyDS9G2TTX9p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/372089863747/locations/europe-west4/models/477289201524539392@1'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuned model name\n",
    "tuned_model_name = sft_tuning_job.tuned_model_name\n",
    "tuned_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_s57xpI5o9m0"
   },
   "source": [
    "Use `tuning.TuningJob.list()` to retrieve your tuning jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8QtT3uJ3Jw0N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<vertexai.tuning._supervised_tuning.SupervisedTuningJob object at 0x7f8cbbbe1120> \n",
       " resource name: projects/372089863747/locations/europe-west4/tuningJobs/7765162057824993280]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_tuning_job.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KQmyjjcJ9uz"
   },
   "source": [
    "Your model is automatically deployed as a Vertex AI Endpoint and ready for use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "X9uQD-Ee_h6h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/372089863747/locations/europe-west4/endpoints/2273334848426868736'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuned model endpoint name\n",
    "tuned_model_endpoint_name = sft_tuning_job.tuned_model_endpoint_name\n",
    "tuned_model_endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRPlb4ZO8ulD"
   },
   "source": [
    "## Test the tuned model with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "OhfU4wTOtH1y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<vertexai.generative_models.GenerativeModel object at 0x7f8cbae09d50>\n"
     ]
    }
   ],
   "source": [
    "tuned_model = GenerativeModel(tuned_model_endpoint_name)\n",
    "print(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "S1q1PT2zJRO9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"You can store TensorFlow checkpoints on Google Cloud Storage (GCS) during training using the `tf.keras.callbacks.ModelCheckpoint` callback with a GCS path.  Here\\'s a breakdown of how to do it:\\n\\n```python\\nimport tensorflow as tf\\nfrom google.cloud import storage\\n\\n# 1. Define your model\\nmodel = tf.keras.models.Sequential([\\n    # ... your model layers ...\\n])\\nmodel.compile(optimizer=\\'adam\\', loss=\\'mse\\')\\n\\n# 2. Define the GCS path for your checkpoints\\nGCS_BUCKET_NAME = \\\"your-gcs-bucket-name\\\"  # Replace with your bucket name\\nGCS_CHECKPOINT_PATH = f\\\"gs://{GCS_BUCKET_NAME}/checkpoints/model_{{epoch:02d}}/\\\"\\n\\n\\n# 3. Create the ModelCheckpoint callback\\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(\\n    filepath=GCS_CHECKPOINT_PATH,\\n    save_freq=\\'epoch\\',  # Save every epoch\\n    save_weights_only=False, # Saves the entire model (architecture + weights)\\n    # Optionally add more arguments like monitor=\\'val_loss\\', save_best_only=True\\n)\\n\\n# 4. (Optional) Set up TF to authenticate with GCS\\n#  If you\\'re running on a Google Cloud environment (e.g., Vertex AI, Compute Engine\\n#  with a service account), authentication is usually automatic.  Otherwise:\\n\\n# a) Set GOOGLE_APPLICATION_CREDENTIALS environment variable\\n# import os\\n# os.environ[\\\"GOOGLE_APPLICATION_CREDENTIALS\\\"] = \\\"path/to/your/service_account.json\\\"\\n\\n\\n# b) Or, use the `google.auth` library to explicitly set credentials:\\n# from google.auth import default\\n# try:\\n#     credentials, project = default()\\n#     storage_client = storage.Client(credentials=credentials)\\n# except Exception as e:\\n#     print(f\\\"Error setting up authentication: {e}\\\")\\n#     exit(1)\\n\\n\\n\\n\\n# 5. Train your model with the callback\\nhistory = model.fit(\\n    x_train,\\n    y_train,\\n    epochs=10,\\n    validation_data=(x_val, y_val),\\n    callbacks=[checkpoint_callback]\\n)\\n\\n\\n# Example to load a specific checkpoint:\\n# model = tf.keras.models.load_model(\\\"gs://your-gcs-bucket-name/checkpoints/model_05/\\\") # Load the model from epoch 05\\n\\n\\n# Example to download checkpoints locally (if needed):\\n# def download_blob(bucket_name, source_blob_name, destination_file_name):\\n#      \\\"\\\"\\\"Downloads a blob from the bucket.\\\"\\\"\\\"\\n#      storage_client = storage.Client()\\n#      bucket = storage_client.bucket(bucket_name)\\n#      blob = bucket.blob(source_blob_name)\\n#      blob.download_to_filename(destination_file_name)\\n# download_blob(\\\"your-gcs-bucket-name\\\", \\\"checkpoints/model_05/\\\", \\\"local_checkpoint\\\")\\n\\n```\\n\\n\\n**Key explanations and improvements:**\\n\\n* **`GCS_CHECKPOINT_PATH`:** This is now a formatted string using an f-string and the  `{epoch:02d}`  placeholder. This saves each epoch\\'s checkpoint in a separate subdirectory, preventing overwriting and allowing easy access to specific epochs.  For example, `gs://your-bucket/checkpoints/model_01/`, `gs://your-bucket/checkpoints/model_02/`, etc.\\n* **`save_weights_only=False`:**  Saves the entire model (architecture + weights), making loading the model later much simpler.\\n* **Authentication:**  The code now includes more robust options for authentication, handling both automatic authentication within Google Cloud environments and explicit credential setting using environment variables or the `google.auth` library.\\n* **Loading a checkpoint:** Demonstrates how to load a specific checkpoint from GCS.\\n* **Downloading checkpoints (Optional):** Provides a function to download checkpoints locally if needed.\\n* **Error Handling:**  Added basic error handling during authentication setup.\\n* **Clarity and Comments:** Improved code comments and explanations for better understanding.\\n\\n\\nRemember to replace `\\\"your-gcs-bucket-name\\\"` with your actual GCS bucket name.  Ensure your bucket exists and you have the necessary permissions to write to it.  Also, ensure that the TensorFlow version you are using supports saving checkpoints directly to GCS.  If you\\'re using an older version, you might need to manually save the checkpoints locally and then upload them to GCS.\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  citation_metadata {\n",
      "    citations {\n",
      "      start_index: 2023\n",
      "      end_index: 2211\n",
      "      uri: \"https://stackoverflow.com/questions/51526572/google-datalab-read-from-cloud-storage\"\n",
      "    }\n",
      "    citations {\n",
      "      start_index: 2150\n",
      "      end_index: 2331\n",
      "      uri: \"https://www.intertec.io/blog/python-script-on-gcp-batch\"\n",
      "    }\n",
      "  }\n",
      "  avg_logprobs: -0.23563459954702082\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 14\n",
      "  candidates_token_count: 1018\n",
      "  total_token_count: 1032\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I store a TensorFlow checkpoint on Google Cloud Storage while training?\"\n",
    "response = tuned_model.generate_content(question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the response from model in the Cloud Storage bucket \n",
    "from google.cloud import storage\n",
    "\n",
    "with open('tuned_model_qa_response.txt', \"w+\") as output:\n",
    "    image_content = output.write(response.text)\n",
    "    output.close()\n",
    "\n",
    "storage_client = storage.Client()\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-model-dataset\"\n",
    "bucket = storage_client.get_bucket(BUCKET_NAME)\n",
    "blob = bucket.blob('tuned_model_qa_response.txt')\n",
    "blob.upload_from_filename('tuned_model_qa_response.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the **Task 6. Test the tuned model with a prompt** section of the lab and click  **Check my progress** to verify the __Test the tuned model with a prompt__ objective."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
